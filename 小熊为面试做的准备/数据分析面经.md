面经

### 阿里数据研发

#### a.16年3月 https://blog.csdn.net/xiaozhouchou/article/details/50922181

一面技术面大概是30多分钟 

1.**MapReduce二次排序**  

**答：**先了解下二次排序吧，在MapReduce操作时，我们知道传递的<key,value>会按照key的大小进行排序，最后输出的结果是按照key排过序的。有的时候我们在key排序的基础上，对value也进行排序。这种需求就是二次排序。数据处理分为四个阶段：（1）Mapper任务会接收输入分片，然后不断的调用map函数，对记录进行处理。处理完毕后，转换为新的<key,value>输出。（2）对map函数输出的<key, value>调用分区函数，对数据进行分区。不同分区的数据会被送到不同的Reducer任务中。（3）对于不同分区的数据，会按照key进行排序，这里的key必须实现WritableComparable接口。该接口实现了Comparable接口，因此可以进行比较排序。（4）对于排序后的<key,value>，会按照key进行分组。如果key相同，那么相同key的<key,value>就被分到一个组中。最终，每个分组会调用一次reduce函数。（5）排序、分组后的数据会被送到Reducer节点。在MapReduce的体系结构中，我们没有看到对value的排序操作。怎么实现对value的排序哪？这就需要我们变通的去实现这个需求。

**变通手段：**我们可以把key和value联合起来作为新的key，记作newkey。这时，newkey含有两个字段，假设分别是k,v。这里的k和v是原来的key和value。原来的value还是不变。这样，value就同时在newkey和value的位置。我们再实现newkey的比较规则，先按照key排序，在key相同的基础上再按照value排序。在分组时，再按照原来的key进行分组，就不会影响原有的分组逻辑了。最后在输出的时候，只把原有的key、value输出，就可以变通的实现了二次排序的需求。

2.**数据挖掘十大算法** 

决策树的C4.5算法以及其核心ID3算法，svm,k-means算法** 

要求能够分析算法原理，熟悉基本应用，实现并阐述

3.**hbase**  

大致了解 即可

4.**事务处理** 

什么时候用到事务，平时我们一般怎么控制事务，一般借助什么控制，优点 

java事务总结http://lavasoft.blog.51cto.com/62575/53815/   答主主要阐述了sql事物以及java事物处理、常见的事务处理手段 

5.**sql调优/优化** 

6.**java内存块以及关于多线程的理解** 

多线程就不多说了，各种面经上面都能看到详细答案，java内存块的话主要说说**堆、栈、静态区**以及代码区用来存放什么，说的详细点的话还可以扯扯垃圾回收器的机制 

7.**统计学相关** 

二面项目面大概持续五十分钟左右 

机器学习算法做的项目 

什么是**特征选取，怎么选块，svm的核函数**如何推出来，

如何**自定义核函数，二分类和多分类中参数选择**等等问题，因为要说算法推导过程，所以最好是准备纸笔 

如果**矩阵太大如何解决**等等很细的问题 ，反正就针对项目给你提很多问题，问的很细

#### b.14年10月 https://blog.csdn.net/u013599826/article/details/40016205

交叉面为数据研发

一面

- 熟练掌握基本的SQL语句；因为有一道笔试题目：给定一个表，共四列：user_id, brand_id, time, cnt(花的钱数)。从这个表里面选出用户B对每个品牌brand购买的总额度。 如果需要处理字符串的话，答主会用ODPS-SQL里面的UDF 
- 我觉得阿里应该用自己的ODPS-SQL（类似于Hive）进行数据研发，虽然这个平台挺复杂的，但是面试的时候的要求并不高。只要掌握基本的内建函数和SQL语句就行了：select, group by…。我在比赛过程中，写过几万行SQL代码（去重之后几千行），没有用到过索引和视图；经常用到内建函数，偶尔使用UDF（用户自定义函数）。但是，写的代码不包含索引、视图和UDF。也没有考优化（其实我也不懂）。
- 有数据研发方面的相关经历，面试官似乎很注重这一项。答主参加过阿里巴巴大数据竞赛，问做了什么，用什么模型、算法做的，准确率是多少。（这块讨论时间最多） 
- 对数据研发有一些自己的看法。这个很关键，一定要思路清晰。我主要在讲比赛中的模型：数据的预处理->训练集、预测集->特征提取->进一步处理->正负样本比例->训练->预测。
- 当然会用写MapReduce的话就过更好了。阿里的平台提供了MapReduce，估计工作中会用到。这边有个详细的介绍：[超级啰嗦版ODPS MapReduce入门](http://beader.me/2014/05/05/odps-mapreduce/)

二面项目面

主要在聊比赛相关的事情，以及自己对数据的理解。“比赛的时候，我们每天都要盯着数据提取特征。如果，仅仅把这个当作数字来看，确实很枯燥。但是，我们会把它当作一种用户行为对待和分析。这样就变得很有趣了。比如，数据清洗后，我看到某个用户每天都在点击某一个品牌，他就是不买，很显然这就是屌丝；有些人一直在购买，明显的高富帅啊。”  

三面HR面

聊到了：平时怎样提高自身技术能力；自己的优缺点；阿里巴巴的花名等等。
面试过程中，主要强调了两点（用自己的经历）：

- 我很喜欢跟别人讨论问题，这样总会得到意外的收获。并且，还举了项目、竞赛以及平时的例子。甚至，我还说了，刚才技术面试官的问题我没有回答上来，但是，私下与其他面试的同学（我不认识）讨论过程中，我就豁然开朗了。
- 把工作当作生活的一部分，愉快地工作。这个主要说了，我在比赛过程中，怎样把一些无聊的事情做成很有意思的事情。

总结：

对于，基础比较扎实的人，那就让面试官随便问吧。不过，我觉得任何人都有可能别问死的，因为他们想通过这种方式看看你的掌握深度。
对于我呢，基础知识一般：数据结构、排序算法和递归，能写出来；操作系统，懂一些基本理论；计算机网络，懂一些基本概念和理论。就只能充分发挥自己的竞赛、项目、论文和专利的优势了。
面试过程中，有一点很重要，把握面试官的兴趣点，并将面试官带入自己的优势。当然，如果自己的优势不是面试官非常了解的领域，但是面试官又比较感兴趣，那就更好了。对于我的几位面试官，聊天的时候，我注意到，面试官1对我的论文和专利感兴趣，面试官2和面试官4对阿里巴巴大数据竞赛感兴趣，面试官3对我的基础能力感兴趣，HR对合作能力感兴趣。面试官3只想问我的基础，虽然多次尝试把他带到我的优势（数据挖掘和分布式）上面来，但是，都被他强制带回去了。其他几位面试官，都是被我有意识地将话题转移到阿里巴巴大数据竞赛上面。正好他们都没有深入了解过这个竞赛，对此有一定的兴趣；然后，大部分时间都在讨论这些内容了。
总而言之，把自己的优势发挥到极致。

#### c.15年5月 https://blog.csdn.net/u014297175/article/details/45743127

1.**java的多态** 

向上转型，向下转型，接口 

2.**java的反射** 

3.**对于hadoop的研究到了哪一步** 

4.**mapreduce的工作机制** 

5.**以一个wordcount的例子来问问题，map输出后，下一步reduce该怎么进行，并且问了我多个reducer的情况，这是对于map的输出该如何处理**，这部分大体上就是个shuffle阶段，但是《Hadoop权威指南》中一直没有写明白 

6.**对linux管道操作有什么理解**

答主说出了命令形式，但是她其实不了解内部实现机制，然后用java的IO知识讲了一下自己的理解，大体就是前一个命令从文件中输入流到内存，后一个命令从内存中读出来，就是一个重定向的问题，大体就是这个意思了，其实后来回来查阅，大体上原理是这样的，但是如果当时把内存替换成管道，大体上就差不多了。7.**问了对数据结构内部的知识**

比如linkedlist，简单讲讲，其实这也是我在简历上写的对数据结构内部了解，于是我介绍了下它的内部实现机理，并将其与ArrayList作了比较，当然是基于java语言的，总感觉面试官其实不是很懂java，期间他也不做多的提问，就我讲完了就算了。

8.**几个简单的推荐算法**

主要还是简历上面的，KNN，以及k-means聚类，我大体上说出个所以然，然后对于之前的一个推荐项目，介绍了一下算法实现的流程，面试官就细细听着，也不作任何评价。

### d.16年9月笔试

https://wenku.baidu.com/view/cbecab896bd97f192379e97d.html

 https://blog.csdn.net/hjnth/article/details/52504224

3道编程题 

1、题目建议使用Hive，但没学过，故使用MYSQL解答。  考察SQL的开窗 分区 排序  

2、算法考察：提取 替换 

3.MapReduce算法简述：给定一个数据关系，要求简述其算法过程。 

把三个公司大数据研发岗问题综合了

https://blog.csdn.net/My_Despicable/article/details/78131077

十个公司的面试经历，java比较多，作者技术扎实，有许多问题可以参考

http://www.cnblogs.com/DarrenChan/p/9027258.html

## Tableau

https://blog.csdn.net/enohtzvqijxo00atz3y8/article/details/79285878

https://www.w3cschool.cn/tableau/

## MapReduce

简单介绍MapReducehttp://blog.jobbole.com/79255/

https://blog.csdn.net/tongxinzhazha/article/details/62418306

## Hive

Hive总结(零)Hive的基础知识https://blog.csdn.net/tongxinzhazha/article/details/55253288

Hive总结(一)Hive 2.1.0本地模式搭建教程https://blog.csdn.net/tongxinzhazha/article/details/54381304

Hive总结(二)Hive数据导入的三种方式https://blog.csdn.net/tongxinzhazha/article/details/55189111

Hive总结(三)内部表和外部表的区别https://blog.csdn.net/tongxinzhazha/article/details/56282386

Hive总结(五)表的基本操作https://blog.csdn.net/tongxinzhazha/article/details/68062941

Hive总结(六)表的三种连接方式https://blog.csdn.net/tongxinzhazha/article/details/68928016

Hive 总结(七)hive导出数据的三种方式https://blog.csdn.net/tongxinzhazha/article/details/69388120

HDFS基础操作一览https://blog.csdn.net/tongxinzhazha/article/details/62043551

#### Hbase与Hive的区别与联系

共同点：

1.hbase与hive都是架构在hadoop之上的。都是用hadoop作为底层存储

区别：

2.Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 。

3.想象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop,如果是索引访问，就用HBase+Hadoop 。

4.Hive query就是MapReduce jobs可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多。

5.Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑。

6.hive借用hadoop的MapReduce来完成一些hive中的命令的执行

7.hbase是物理表，不是逻辑表，提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。

8.hbase是列存储。

9.hdfs作为底层存储，hdfs是存放文件的系统，而Hbase负责组织文件。

10.hive需要用到hdfs存储文件，需要用到MapReduce计算框架。

## 随机森林

已新建md

## XGboost、lgb、GBDT

看看徐璐学姐的总结

## 线性回归

原理

和PCA比较

## 决策树



## K-means



## 数据挖掘十大经典算法

已新建md

## SQL

已新建md