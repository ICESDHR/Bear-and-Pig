伪代码实现：LR、梯度下降、最小二乘、KNN、Kmeans;

##基本知识：

1）监督与非监督区别；

2）L1L2区别；

3）生成模型和判别模型区别   像贝叶斯，lda 等就是生成模型，计算过概率分布之类的

- 典型的生成模型：朴素贝叶斯、隐马尔可夫模型

- 典型的判别模型：k近邻法、感知机、决策树、逻辑回归、最大熵模型、svm、提升方法、条件随机场

- 生成方法的特点：
  - 生成方法可以还原出联合概率分布P(X,Y)，而判别方法不能
  - 生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型
  - 当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用

- 判别方法的特点：
  - 判别方法直接学习的条件概率P(Y|X)或决策函数f(X)，直接面对预测，往往学习的准确率更高
  - 由于直接学习P(Y|X)或f(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题



##算法的优缺点以及相应解决方案：k-means, KNN, apriori



##算法原理：LR、KNN、k-means、apriori、ID3（C45,CART）、SVM、神经网络，协同过滤，em算法



##常见问题：

1）svm算法的原理、如何组织训练数据、如何调节惩罚因子、如何防止过拟合、svm的泛化能力、增量学习

2）神经网络参数相关。比如，参数的范围？如何防止过拟合？隐藏层点的个数多了怎样少了怎样？什么情况下参数是负数？

3）为什么要用逻辑回归？

4）决策树算法是按什么来进行分类的?

5) 朴素贝叶斯公式

6) 讲em算法

7）svm中rbf核函数与高斯和函数的比较

8）说一下SVM的实现和运用过程

9）谈谈DNN

10）简单说说决策树分析

11）推荐系统中基于svd方法

12）SVM有哪些优势，（x,y,z）三个特征如何用径向基核函数抽取第四维特征

13）userCF和ItemCF在实际当中如何使用,提供具体操作，以及它们的优势（推荐系统）

14）如何用Logic regression建立一个广告点击次数预测模型

15）举一个适合采用层次分析法的例子

17）关联分析中的极大频繁项集；FP增长算法

18）线性分类器与非线性分类器的区别及优劣

19）特征比数据量还大时，选择什么样的分类器

20）对于维度很高的特征，你是选择线性还是非线性分类器

21) 对于维度极低的特征，你是选择线性还是非线性分类器

22) 如何解决过拟合问题

23)  L1和L2正则的区别，如何选择L1和L2正则

24) 随机森林的学习过程

25) 随机森林中的每一棵树是如何学习的

26) 随机森林学习算法中CART树的基尼指数是什么

27)支持向量机、图模型、波尔茨曼机，内存压缩、红黑树、并行度

28） 如何搭建一个推荐平台，给出具体的想法，
29） 实现一个中文输入法

30） k-meanshift的机制，能不能用伪码实现
31）实现最小二乘法。